{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BMugo84/tensorflow-object-detection/blob/collab/tfod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHilWQVcdG62"
      },
      "source": [
        "# Object Detection for Airtime Scratchcard Digits\n",
        "\n",
        "## Introduction\n",
        "Hello everyone! In this project, I will focus on the task of converting Safaricom and Telkom scratchcard airtime images into digits that can be used to load airtime. In the past, there was an app called \"RechargeKing\" that allowed users to load airtime by capturing images of scratchcards. However, recent changes in the fonts of Safaricom and Telkom scratch cards have rendered the app obsolete as the developers did not update it.\n",
        "\n",
        "## Problem Definition\n",
        "The problem I aim to solve is the digit recognition from scratchcard images. I want to create a solution that can automatically extract the airtime digits from these images, allowing users to easily load airtime without manual input.\n",
        "\n",
        "## Solution\n",
        "To tackle this problem, I will leverage Nicholas Renotte's TensorFlow Object Detection course, which provides a comprehensive guide on using TensorFlow for object detection. This course will serve as my foundation to build an object detection model capable of recognizing and extracting the digits from scratchcard images. I will use Python for coding and follow the principles outlined in the course.\n",
        "\n",
        "Let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZaaqtuhdG66"
      },
      "source": [
        "# Steps to Achieve Object Detection\n",
        "\n",
        "1. **Install and Setup**: We'll start by setting up our development environment and installing the necessary libraries, including TensorFlow.\n",
        "\n",
        "2. **Collect Images and Label**: Next, we'll gather a dataset of images that contains the objects we want to detect. We'll also label these objects to train our model effectively.\n",
        "\n",
        "3. **Training Models**: The heart of object detection is training models. I'll explain how to use pre-trained models or train custom ones to identify objects in images.\n",
        "\n",
        "4. **Detecting Objects**: Once our models are trained, we'll apply them to real-world images to detect and locate objects accurately.\n",
        "\n",
        "5. **Freezing and Conversion**: We'll discuss how to freeze and convert our trained model into a format suitable for deployment.\n",
        "\n",
        "6. **Performance Tuning**: Object detection isn't just about accuracy; it's also about performance. We'll optimize our models for speed and efficiency.\n",
        "\n",
        "7. **Packaging**: Finally, I'll guide you on packaging your object detection solution for practical use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7fyTBqgdG66"
      },
      "source": [
        "I plan on doing most of the work here then the heavy lifting will be done on collab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMqbLpJwdG66"
      },
      "source": [
        "# 1. **Install and Setup**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToeUDsYTdG67"
      },
      "outputs": [],
      "source": [
        "# # create venv environment\n",
        "# !python -m venv tfod\n",
        "\n",
        "# # activate tfod env\n",
        "# !source tfod/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JcJ5BS4dG68"
      },
      "outputs": [],
      "source": [
        "# # upgrade pip\n",
        "# !python -m pip install --upgrade pip\n",
        "\n",
        "# # install ipykernel\n",
        "# !pip install ipykernel\n",
        "\n",
        "# # assosiate ipykernel to tfod env where name is the name of your virtual environment\n",
        "# !python -m ipykernel install --user --name=tfod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_191BsZdG68"
      },
      "source": [
        "\n",
        "# 2. **Collect Images and Label**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCD_Pf_CdG68"
      },
      "source": [
        "We will be using a number of scratchcard pictures(already used) and label them. right now i have about 50 so they should suffice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir2jLtmZdG69",
        "outputId": "1c530bde-34b1-42b0-a43d-d276ab9e5ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\bm\\tensorflow-object-detection\\tfod\\lib\\site-packages (4.8.1.78)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\bm\\tensorflow-object-detection\\tfod\\lib\\site-packages (from opencv-python) (1.26.0)\n"
          ]
        }
      ],
      "source": [
        "# install opencv\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1cSCKVEdG6-"
      },
      "outputs": [],
      "source": [
        "# import opencv\n",
        "import cv2\n",
        "\n",
        "# import uuid\n",
        "import uuid\n",
        "\n",
        "# import os\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAxdX-WPdG6-"
      },
      "source": [
        "the IMAGES_PATH will host our images and corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqh4mfamdG6-"
      },
      "outputs": [],
      "source": [
        "# make a folder for images\n",
        "IMAGES_PATH =  os.path.join('tensorflow','workspace','images', 'collectedimages')\n",
        "\n",
        "if not os.path.exists(IMAGES_PATH):\n",
        "    if os.name == 'posix':\n",
        "        !mkdir -p {IMAGES_PATH}\n",
        "    if os.name == 'nt':\n",
        "        !mkdir {IMAGES_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qaUFw6IdG6-"
      },
      "source": [
        "I used 40 images of scratch cards for labeling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUxG6DaGdG6-"
      },
      "source": [
        "## 2.1 Label images using [labelImg](https://github.com/HumanSignal/labelImg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rju6trCHdG6_"
      },
      "source": [
        "install pyqt5 for labelimg gui rendering and lxml for handling xml templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VI7WebIdG6_"
      },
      "outputs": [],
      "source": [
        "# install pyqt5 lxml\n",
        "!pip install --upgrade pyqt5 lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXwAB1Q7dG6_"
      },
      "outputs": [],
      "source": [
        "# create a folder where the labelimg repo will be clones into\n",
        "LABELIMG_PATH = os.path.join('tensorflow', 'labelimg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYJVbJ8FdG6_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# clone the git repo into the new folder about 200MB\n",
        "if not os.path.exists(LABELIMG_PATH):\n",
        "    !mkdir {LABELIMG_PATH}\n",
        "    !git clone https://github.com/HumanSignal/labelImg.git {LABELIMG_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nfqp1kfdG6_"
      },
      "outputs": [],
      "source": [
        "# get into the folder and run the command shown\n",
        "if os.name == 'posix':\n",
        "    !cd {LABELIMG_PATH} && make qt5py3\n",
        "if os.name == 'nt':\n",
        "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apyvVnVLdG7A",
        "outputId": "4391ff67-bedb-4fe7-a4f0-bf7cda12b77f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203326.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203326.xml\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203333.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203333.xml\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203340.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203340.xml\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203347.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203347.xml\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203359.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203359.xml\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203406.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203406.xml\n",
            "Cancel creation.\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203420.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203420.xml\n",
            "Image:C:\\Users\\BM\\tensorflow-object-detection\\tensorflow\\workspace\\images\\collectedimages\\IMG_20231009_203430.jpg -> Annotation:C:/Users/BM/tensorflow-object-detection/tensorflow/workspace/images/collectedimages\\IMG_20231009_203430.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-10T19:47:55.777ZE [7376:ShellIpcClient] shell_ipc_client.cc:138:Connect Can't connect to socket at: \\\\.\\Pipe\\GoogleDriveFSPipe_BM_shell\n",
            "2023-10-10T19:47:55.812ZE [7376:ShellIpcClient] shell_ipc_client.cc:621:operator() Failed to connect to the server: NOT_FOUND: Can't connect to socket at: \\\\.\\Pipe\\GoogleDriveFSPipe_BM_shell [type.googleapis.com/drive.ds.Status='UNAVAILABLE_RESOURCE']\n",
            "=== Source Location Trace: ===\n",
            "apps/drive/fs/ipc/shell_ipc_client.cc:139\n",
            "\n",
            "2023-10-10T19:47:55.812ZE [16936:ShellIpcClient] shell_ipc_client.cc:138:Connect Can't connect to socket at: \\\\.\\Pipe\\GoogleDriveFSPipe_BM_shell\n",
            "2023-10-10T19:47:55.812ZE [16936:ShellIpcClient] shell_ipc_client.cc:621:operator() Failed to connect to the server: NOT_FOUND: Can't connect to socket at: \\\\.\\Pipe\\GoogleDriveFSPipe_BM_shell [type.googleapis.com/drive.ds.Status='UNAVAILABLE_RESOURCE']\n",
            "=== Source Location Trace: ===\n",
            "apps/drive/fs/ipc/shell_ipc_client.cc:139\n",
            "\n",
            "2023-10-10T19:47:55.812ZE [7672:ShellIpcClient] shell_ipc_client.cc:138:Connect Can't connect to socket at: \\\\.\\Pipe\\GoogleDriveFSPipe_BM_shell\n",
            "2023-10-10T19:47:55.812ZE [7672:ShellIpcClient] shell_ipc_client.cc:621:operator() Failed to connect to the server: NOT_FOUND: Can't connect to socket at: \\\\.\\Pipe\\GoogleDriveFSPipe_BM_shell [type.googleapis.com/drive.ds.Status='UNAVAILABLE_RESOURCE']\n",
            "=== Source Location Trace: ===\n",
            "apps/drive/fs/ipc/shell_ipc_client.cc:139\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# open the app\n",
        "!cd {LABELIMG_PATH} && python labelImg.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ4OO3uEdG7A"
      },
      "source": [
        "typical labeling\n",
        "\n",
        "![Screenshot 2023-10-10 230307.png](<attachment:Screenshot 2023-10-10 230307.png>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy9YYLzSdG7A"
      },
      "source": [
        "## **2.2 move them into a training and testing partition**\n",
        "\n",
        "cretate two folders under images. one for training and one for testing.\n",
        "we will split them 80/20 where we have 32 images for training and 8 images for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MCCanuIjdG7A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "TRAINING_PATH = os.path.join('tensorflow', 'workspace','images', 'train')\n",
        "TESTING_PATH = os.path.join('tensorflow', 'workspace','images', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TVfdwHy7dG7A"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(TRAINING_PATH) or not os.path.exists(TESTING_PATH):\n",
        "    if os.name == 'posix':\n",
        "        !mkdir -p {TRAINING_PATH}\n",
        "        !mkdir -p {TESTING_PATH}\n",
        "    if os.name == 'nt':\n",
        "        !mkdir {TRAINING_PATH}\n",
        "        !mkdir {TESTING_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVO9oPJZdG7B"
      },
      "source": [
        "copy-paste images plus respective annotations to train and test folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrbnBa74e323",
        "outputId": "14cb41eb-5a9c-4ddb-861e-0f3c644c7263"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since they are all in local machine, we will upload them from google drive\n",
        "#/content/tensorflow/workspace/images   /content/drive/MyDrive/tensorflow-object-detection-main/tensorflow/workspace/images\n",
        "!cp -r /content/drive/MyDrive/tensorflow-object-detection-main/tensorflow/workspace/images /content/tensorflow/workspace/\n"
      ],
      "metadata": {
        "id": "Wm4bezTIgPZg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/tensorflow/workspace/images/test/\n"
      ],
      "metadata": {
        "id": "jEbNCJWmiTtM",
        "outputId": "07f367ef-6f2c-42f0-8975-164daea4adb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_20231009_203326.jpg  IMG_20231009_203340.jpg  IMG_20231009_203359.jpg  IMG_20231009_203420.jpg\n",
            "IMG_20231009_203326.xml  IMG_20231009_203340.xml  IMG_20231009_203359.xml  IMG_20231009_203420.xml\n",
            "IMG_20231009_203333.jpg  IMG_20231009_203347.jpg  IMG_20231009_203406.jpg  IMG_20231009_203430.jpg\n",
            "IMG_20231009_203333.xml  IMG_20231009_203347.xml  IMG_20231009_203406.xml  IMG_20231009_203430.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OInWDX1qhN78",
        "outputId": "953e00a9-0af3-479c-cc0d-82edae9583ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgBV1rzSdG7B"
      },
      "source": [
        "\n",
        "# 3. **Training Models**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hc4BitYdG7B"
      },
      "source": [
        "### **Training**\n",
        "In order to leverage a custom TFOD model, we need to finetune /train a new computer vision model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fE5sQ1NdG7B"
      },
      "source": [
        "### **Evaluation**\n",
        "Once you have trained a model, ideally you want to take a look at how well it's performing. we normally take a look at:\n",
        "\n",
        "Precision: TP/(TP+FP)\n",
        "*what propotion of my detections were correct?*\n",
        "\n",
        "Recall: TP/ (TP+FN)\n",
        "*what propotion of the actual objects did I capture?*\n",
        "\n",
        "Loss:\n",
        "*How well is the model performing against the data provided?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU3lVIM7dG7B"
      },
      "source": [
        "# TensorFlow Model Zoo: Making Model Choices\n",
        "\n",
        "Within the TensorFlow Model Zoo, you'll find a diverse array of models at your disposal, each designed for specific tasks. However, when making your selection, it's crucial to understand the trade-off that often comes into play.\n",
        "\n",
        "In the realm of object detection and beyond, the rule of thumb is simple:\n",
        "\n",
        "- Opting for faster detections often means sacrificing some degree of accuracy.\n",
        "- On the flip side, if you prioritize higher accuracy, be prepared for slightly slower detection times.\n",
        "\n",
        "Balancing these factors is key to choosing the right model for your particular use case. In the following sections, we'll delve deeper into the considerations that guide your model selection within the TensorFlow Model Zoo.\n",
        "\n",
        "\n",
        "Current choices for this project:\n",
        "\n",
        "1. **SSD MobileNet V2 FPNLite 640x640**:\n",
        "   - Speed: Relatively fast due to MobileNet architecture.\n",
        "   - Accuracy: 28.2 mAP (mean Average Precision), which is moderate.\n",
        "   - Resolution: 640x640.\n",
        "   - Suitable for scenarios where speed is more critical than very high accuracy.\n",
        "\n",
        "2. **SSD ResNet50 V1 FPN 640x640 (RetinaNet50)**:\n",
        "   - Speed: Moderate speed due to ResNet50 backbone.\n",
        "   - Accuracy: 34.3 mAP, which is relatively good.\n",
        "   - Resolution: 640x640.\n",
        "   - A balanced choice for accuracy and speed.\n",
        "\n",
        "3. **SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)**:\n",
        "   - Speed: Slower than the 640x640 version.\n",
        "   - Accuracy: 38.3 mAP, which is better.\n",
        "   - Higher resolution (1024x1024) can provide better accuracy but at the cost of speed.\n",
        "   - Choose this if you need higher accuracy and have the hardware to support it.\n",
        "\n",
        "4. **SSD ResNet101 V1 FPN 640x640 (RetinaNet101)**:\n",
        "   - Speed: Similar to ResNet50.\n",
        "   - Accuracy: 35.6 mAP, which is quite good.\n",
        "   - Resolution: 640x640.\n",
        "   - Offers a good balance of speed and accuracy, similar to the RetinaNet50 models.\n",
        "\n",
        "5. **SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)**:\n",
        "   - Speed: Slower than the 640x640 version.\n",
        "   - Accuracy: 39.5 mAP, which is the highest among the models listed.\n",
        "   - Resolution: 1024x1024.\n",
        "   - Opt for this if you require the highest accuracy and have the necessary hardware capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7xz9sIFdG7B"
      },
      "source": [
        "When choosing an object detection model, there are several critical factors to consider:\n",
        "\n",
        "1. **Deployment Platform**: Think about where you intend to deploy this model. Will it run on a computer, a smartphone, a Raspberry Pi, or a different device? The hardware resources available on the deployment platform will impact your choice.\n",
        "\n",
        "2. **Frame Processing Time**: Consider the time you're willing to allocate for processing each frame. Depending on your use case, you may require real-time or near-real-time processing. Faster models can be essential for applications where speed is of the essence.\n",
        "\n",
        "3. **Accuracy Requirements**: Evaluate how accurate your model needs to be. In some cases, high accuracy is crucial, while in others, a slightly lower accuracy may be acceptable if it allows for faster processing.\n",
        "\n",
        "Taking these factors into account, if you prioritize faster processing and your deployment platform has limited resources, `SSD MobileNet V2 FPNLite 640x640` could be an excellent choice. It strikes a balance between speed and accuracy, making it suitable for scenarios where real-time or near-real-time processing is desired.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJiacWcUdG7C"
      },
      "source": [
        "## 3.1 **Setup paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pZ6bs6OTdG7C"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVqgTPJAdG7C"
      },
      "source": [
        "we are going to download `SSD MobileNet V2 FPNLite 640x640` and place it in our folder. this arrangement will be useful in collab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "p-uHCuaIdG7C"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'spinenet49mobile'\n",
        "PRETRAINED_MODEL_URL = 'https://storage.googleapis.com/tf_model_garden/vision/retinanet/spinenet49mobile.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JGhCjvoudG7C"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('tensorflow', 'scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('tensorflow', 'models'),\n",
        "    'ANNOTATION_PATH': os.path.join('tensorflow', 'workspace', 'annotations'),\n",
        "    'IMAGE_PATH': os.path.join('tensorflow', 'workspace', 'images'),\n",
        "    'MODEL_PATH': os.path.join('tensorflow', 'workspace', 'models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('tensorflow', 'workspace', 'pretrained_models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('tensorflow', 'workspace','models', CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH': os.path.join('tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH': os.path.join('tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH': os.path.join('tensorflow', 'workspace')\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wKM74UabdG7D"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG': os.path.join('tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tDnJUA2HdG7D"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYBL57wwdG7D"
      },
      "source": [
        "## 3.2 **Download TF Models Pretrained Models from TensorFlow Model Zoo and Install TFOD.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMOnveCcdG7D"
      },
      "outputs": [],
      "source": [
        "# https://github.com/tensorflow/models/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug67ynVrdG7I",
        "outputId": "8931de0d-009a-4a94-b0d2-f6f238a9e9e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# due to unexpected and irreversible errors, downgrade to tensorflow 2.13.0\n",
        "!pip install tensorflow==2.13.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jeH6dG9ZdG7I"
      },
      "outputs": [],
      "source": [
        "# install wget\n",
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jaY-28aSdG7J",
        "outputId": "dd07e46c-83a5-4fea-ca2d-ea31412a0296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tensorflow/models'...\n",
            "remote: Enumerating objects: 87993, done.\u001b[K\n",
            "remote: Counting objects: 100% (1701/1701), done.\u001b[K\n",
            "remote: Compressing objects: 100% (704/704), done.\u001b[K\n",
            "remote: Total 87993 (delta 1091), reused 1549 (delta 979), pack-reused 86292\u001b[K\n",
            "Receiving objects: 100% (87993/87993), 601.16 MiB | 24.95 MiB/s, done.\n",
            "Resolving deltas: 100% (63002/63002), done.\n"
          ]
        }
      ],
      "source": [
        "# clone the tfod garden into APIMODEL_PATH\n",
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/setup.py /content/tensorflow/models/research/object_detection/packages/tf2"
      ],
      "metadata": {
        "id": "YIlPa45fwvZC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jT4dZwRjdG7J",
        "outputId": "879d7081-b960-4ba9-a7ab-8bb59a492f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Processing /content/tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.51.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython==3.0.0 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools==2.0.6 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: tf-models-official==2.13.2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.13.2)\n",
            "Requirement already satisfied: tensorflow-io==0.32.0 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.32.0)\n",
            "Requirement already satisfied: keras==2.13.1 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.13.1)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0.6->object-detection==0.1) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0->object-detection==0.1) (0.32.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (2.84.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (4.8.1.78)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (0.15.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-text~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.2->object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.9.9)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.8.4)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.19)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.74)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n",
            "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0->object-detection==0.1) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.2->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.2->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.2->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.2->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.1)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (6.1.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1) (2.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.2->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.2->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.2->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.2->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.13.2->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (1.5.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (6.1.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.2->object-detection==0.1) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.2->object-detection==0.1) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.2->object-detection==0.1) (5.3.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.2->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.2->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.2->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697375 sha256=93ba13749317e8fa9c1403cd1f4b9f62f2553f2601fd8bca420759559b492ebb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bysm4vv_/wheels/98/68/ba/cb9e30e71245301cb10375c6d9cd6e721173a2637f378668be\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ]
        }
      ],
      "source": [
        "# install tensorflow object detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    !cd tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd tensorflow/models/research/slim && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GHN22R6NdG7J",
        "outputId": "5f40216e-1870-4636-ef68-b1c1dc5e88fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-17 12:15:22.698655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1017 12:15:29.397169 137685094653952 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1017 12:15:29.948954 137685094653952 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.18s\n",
            "I1017 12:15:30.470904 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.29s\n",
            "I1017 12:15:31.761400 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.69s\n",
            "I1017 12:15:32.455044 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.69s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.04s\n",
            "I1017 12:15:33.500740 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.01s\n",
            "I1017 12:15:38.510098 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1017 12:15:38.520143 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.06s\n",
            "I1017 12:15:38.581985 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.04s\n",
            "I1017 12:15:38.621880 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.04s\n",
            "I1017 12:15:38.663615 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.24s\n",
            "I1017 12:15:38.909170 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.23s\n",
            "I1017 12:15:39.144522 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.23s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.24s\n",
            "I1017 12:15:39.382494 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.24s\n",
            "I1017 12:15:39.621827 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.23s\n",
            "I1017 12:15:39.857336 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.23s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "I1017 12:15:39.925862 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1017 12:15:40.356776 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1017 12:15:40.357027 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1017 12:15:40.357152 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1017 12:15:40.362946 137685094653952 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1017 12:15:40.420547 137685094653952 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1017 12:15:40.420804 137685094653952 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1017 12:15:40.593055 137685094653952 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1017 12:15:40.593330 137685094653952 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1017 12:15:41.014131 137685094653952 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1017 12:15:41.014392 137685094653952 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1017 12:15:41.463795 137685094653952 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1017 12:15:41.464049 137685094653952 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1017 12:15:42.135407 137685094653952 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1017 12:15:42.135751 137685094653952 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1017 12:15:42.898455 137685094653952 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1017 12:15:42.898769 137685094653952 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1017 12:15:43.794423 137685094653952 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1017 12:15:43.794681 137685094653952 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1017 12:15:44.022339 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1017 12:15:44.190100 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:15:44.310045 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1017 12:15:44.310337 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1017 12:15:44.310458 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1017 12:15:44.314398 137685094653952 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1017 12:15:44.351364 137685094653952 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1017 12:15:44.351608 137685094653952 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1017 12:15:44.605468 137685094653952 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1017 12:15:44.605687 137685094653952 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1017 12:15:44.985978 137685094653952 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1017 12:15:44.986252 137685094653952 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1017 12:15:45.822668 137685094653952 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1017 12:15:45.822934 137685094653952 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1017 12:15:46.378233 137685094653952 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1017 12:15:46.378511 137685094653952 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1017 12:15:46.910671 137685094653952 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1017 12:15:46.910882 137685094653952 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1017 12:15:47.741397 137685094653952 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1017 12:15:47.741663 137685094653952 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1017 12:15:48.125977 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1017 12:15:48.209022 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:15:48.299776 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1017 12:15:48.300041 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1017 12:15:48.300130 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1017 12:15:48.302855 137685094653952 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1017 12:15:48.332762 137685094653952 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1017 12:15:48.333018 137685094653952 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1017 12:15:48.565467 137685094653952 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1017 12:15:48.565730 137685094653952 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1017 12:15:48.999719 137685094653952 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1017 12:15:49.000005 137685094653952 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1017 12:15:49.460885 137685094653952 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1017 12:15:49.461192 137685094653952 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1017 12:15:50.061873 137685094653952 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1017 12:15:50.062155 137685094653952 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1017 12:15:50.707355 137685094653952 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1017 12:15:50.707629 137685094653952 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1017 12:15:51.586851 137685094653952 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1017 12:15:51.587133 137685094653952 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1017 12:15:52.015382 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1017 12:15:52.128801 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:15:52.220263 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1017 12:15:52.220549 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1017 12:15:52.220622 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1017 12:15:52.223387 137685094653952 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1017 12:15:52.257865 137685094653952 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1017 12:15:52.258180 137685094653952 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1017 12:15:52.511806 137685094653952 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1017 12:15:52.512060 137685094653952 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1017 12:15:52.962711 137685094653952 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1017 12:15:52.962977 137685094653952 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1017 12:15:53.367424 137685094653952 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1017 12:15:53.367672 137685094653952 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1017 12:15:54.067710 137685094653952 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1017 12:15:54.067929 137685094653952 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1017 12:15:55.058154 137685094653952 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1017 12:15:55.058500 137685094653952 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1017 12:15:56.488252 137685094653952 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1017 12:15:56.488582 137685094653952 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1017 12:15:57.184334 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1017 12:15:57.334296 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:15:57.492924 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1017 12:15:57.493209 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1017 12:15:57.493339 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1017 12:15:57.496910 137685094653952 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1017 12:15:57.535470 137685094653952 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1017 12:15:57.535704 137685094653952 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1017 12:15:57.825414 137685094653952 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1017 12:15:57.825658 137685094653952 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1017 12:15:58.602143 137685094653952 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1017 12:15:58.602478 137685094653952 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1017 12:15:59.585884 137685094653952 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1017 12:15:59.586308 137685094653952 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1017 12:16:01.676043 137685094653952 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1017 12:16:01.676452 137685094653952 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1017 12:16:03.092573 137685094653952 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1017 12:16:03.092840 137685094653952 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1017 12:16:05.117958 137685094653952 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1017 12:16:05.118268 137685094653952 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1017 12:16:05.822797 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1017 12:16:05.998754 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:16:06.186435 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1017 12:16:06.186704 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1017 12:16:06.186823 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1017 12:16:06.190841 137685094653952 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1017 12:16:06.230236 137685094653952 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1017 12:16:06.230495 137685094653952 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1017 12:16:06.692020 137685094653952 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1017 12:16:06.692317 137685094653952 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1017 12:16:07.677590 137685094653952 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1017 12:16:07.677869 137685094653952 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1017 12:16:08.668994 137685094653952 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1017 12:16:08.669306 137685094653952 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1017 12:16:09.631292 137685094653952 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1017 12:16:09.631497 137685094653952 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1017 12:16:10.653249 137685094653952 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1017 12:16:10.653510 137685094653952 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1017 12:16:12.348074 137685094653952 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1017 12:16:12.348359 137685094653952 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1017 12:16:13.064584 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1017 12:16:13.176765 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:16:13.301266 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1017 12:16:13.301476 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1017 12:16:13.301539 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1017 12:16:13.306359 137685094653952 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1017 12:16:13.348022 137685094653952 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1017 12:16:13.348262 137685094653952 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1017 12:16:13.684972 137685094653952 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1017 12:16:13.685247 137685094653952 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1017 12:16:14.573818 137685094653952 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1017 12:16:14.574087 137685094653952 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1017 12:16:15.350155 137685094653952 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1017 12:16:15.350408 137685094653952 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1017 12:16:16.426415 137685094653952 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1017 12:16:16.426613 137685094653952 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1017 12:16:18.416503 137685094653952 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1017 12:16:18.416776 137685094653952 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1017 12:16:21.828566 137685094653952 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1017 12:16:21.828898 137685094653952 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1017 12:16:23.208324 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1017 12:16:23.424201 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1017 12:16:23.661935 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1017 12:16:23.662211 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1017 12:16:23.662331 137685094653952 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1017 12:16:23.666409 137685094653952 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1017 12:16:23.707916 137685094653952 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1017 12:16:23.708189 137685094653952 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1017 12:16:24.417097 137685094653952 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1017 12:16:24.420084 137685094653952 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1017 12:16:26.062623 137685094653952 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1017 12:16:26.062995 137685094653952 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1017 12:16:27.817748 137685094653952 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1017 12:16:27.818137 137685094653952 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1017 12:16:30.469882 137685094653952 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1017 12:16:30.470386 137685094653952 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1017 12:16:33.378717 137685094653952 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1017 12:16:33.378978 137685094653952 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1017 12:16:36.907670 137685094653952 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1017 12:16:36.907920 137685094653952 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1017 12:16:38.735390 137685094653952 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1017 12:16:38.952625 137685094653952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 59.29s\n",
            "I1017 12:16:39.215038 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 59.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I1017 12:16:39.268990 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1017 12:16:39.271353 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1017 12:16:39.271959 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1017 12:16:39.273665 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1017 12:16:39.275089 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1017 12:16:39.275528 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1017 12:16:39.276649 137685094653952 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 69.993s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "\n",
        "# verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ_LACkBdG7K"
      },
      "outputs": [],
      "source": [
        "# solve for ModuleNotFoundError: No module named 'tensorflow'\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u0pvR1RdG7K",
        "outputId": "68f69717-a0c7-42f3-9036-58ff7dceae73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nTypeError: Descriptors cannot not be created directly.\\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\\n 1. Downgrade the protobuf package to 3.20.x or lower.\\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "solve:\n",
        "TypeError: Descriptors cannot not be created directly.\n",
        "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
        "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
        " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
        " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
        "'''\n",
        "\n",
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2\n",
        "!pip install pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd0QP04AdG7K"
      },
      "outputs": [],
      "source": [
        "# incase there is a tensorflow object detection api error then follow this link https://github.com/tensorflow/models/issues/11085\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install apache-beam avro-python3 contextlib2 Cython lvis pycocotools\n",
        "!pip install protobuf\n",
        "!pip install pyyaml\n",
        "!pip install tensorflow-io\n",
        "!pip install portalocker tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDtQ1EfCdG7K"
      },
      "source": [
        "If the text in a Markdown cell appears too long and you want to hide or shorten it without deleting the content, you can use a combination of techniques:\n",
        "\n",
        "1. **Use a Collapsible Section:** You can create a collapsible section in your Markdown cell by using HTML and JavaScript. This allows you to hide or show content as needed. Here's an example:\n",
        "\n",
        "   ```markdown\n",
        "   <details>\n",
        "   <summary>Click to expand</summary>\n",
        "\n",
        "   Your long text goes here.\n",
        "\n",
        "   </details>\n",
        "   ```\n",
        "\n",
        "   In this example, the long text is initially hidden, and you can click \"Click to expand\" to reveal it.\n",
        "\n",
        "To access your command history, you can use the history command:\n",
        "\n",
        "To load and access command history in a Bash shell on a Windows system (assuming you are using a Bash emulation layer like Git Bash or WSL - Windows Subsystem for Linux), you can use a combination of built-in commands and environment variables. Here's how to do it:\n",
        "\n",
        "1. Open your Bash shell, such as Git Bash or WSL.\n",
        "\n",
        "2. To access your command history, you can use the `history` command:\n",
        "\n",
        "   ```\n",
        "   history\n",
        "   ```\n",
        "\n",
        "   This will display a list of previously executed commands along with line numbers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF0hAw0NdG7L"
      },
      "source": [
        "a list of all command prompts i used while solving issues.\n",
        "<details>\n",
        "<summary>Click to expand</summary>\n",
        "\n",
        "1. `pip list`\n",
        "2. `pip install tensorflow`\n",
        "3. `pip uninstall protobuf matplotlib -y`\n",
        "4. `pip install protobuf matplotlib==3.2`\n",
        "5. `pip install matplotlib`\n",
        "6. `pip install pandas`\n",
        "7. `pip install scipy`\n",
        "8. `pip install object-detection==0.1 apache-beam avro-python3 contextlib2 Cython lvis pycocotools`\n",
        "9.  `pip install matplotlib`\n",
        "10. `pip install protobuf`\n",
        "11. `pip install pyyaml`\n",
        "12. `pip uninstall protobuff`\n",
        "13. `pip install protobuf==3.20.3`\n",
        "14. `pip install tensorflow-io`\n",
        "15. `pip install object-detection==0.1 apache-beam avro-python3 contextlib2 Cython lvis pycocotools tf-models-official>=2.5.1`\n",
        "16. `pip install apache-beam avro-python3 contextlib2 Cython lvis pycocotools tf-models-official>=2.5.1`\n",
        "17. `pip install apache-beam avro-python3 contextlib2 Cython lvis pycocotools`\n",
        "18. `pip install tf-models-official`\n",
        "19. `pip install portalocker`\n",
        "20. `pip install tabulate`\n",
        "21. `pip install tf-models-official`\n",
        "22. `pip install tf-models-official`\n",
        "23. `pip install --upgrade setuptools`\n",
        "24. `pip install tf-models-official`\n",
        "25. `pip install tf-models-official`\n",
        "26. `cd tensorflow`\n",
        "27. `git clone https://github.com/tensorflow/models models`\n",
        "28. `cd models`\n",
        "29. `git clone https://github.com/tensorflow/models`\n",
        "30. `git clone https://github.com/tensorflow/models`\n",
        "31. `cd ..`\n",
        "32. `cd ..`\n",
        "33. `pip uninstall Cython -y`\n",
        "34. `cd tensorflow/models`\n",
        "35. `cd research`\n",
        "36. `protoc object_detection/protos/*.proto --python_out= .`\n",
        "37. `cp object_detection/packages/tf2/setup.py .`\n",
        "38. `python -m pip install .`\n",
        "39. `protoc object_detection/protos/*.proto --python_out= .`\n",
        "40. `protoc object_detection/protos/*.proto --python_out= .`\n",
        "41. `cd ..`\n",
        "42. `cd ..`\n",
        "43. `cd ..`\n",
        "44. `cd models/research`\n",
        "45. `protoc object_detection/protos/*.proto --python_out= .`\n",
        "46. `cp object_detection/packages/tf2/setup.py .`\n",
        "\n",
        "</details>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "YcyZKQ3fdG7L"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ngognpTzdG7L",
        "outputId": "73e5bb6d-c0c9-4d4c-cf8c-e90345938701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-17 12:17:00--  https://storage.googleapis.com/tf_model_garden/vision/retinanet/spinenet49mobile.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.172.207, 172.217.212.207, 142.250.128.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.172.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17629421 (17M) [application/x-tar]\n",
            "Saving to: spinenet49mobile.tar.gz\n",
            "\n",
            "spinenet49mobile.ta 100%[===================>]  16.81M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-17 12:17:01 (122 MB/s) - spinenet49mobile.tar.gz saved [17629421/17629421]\n",
            "\n",
            "ckpt-277200.data-00000-of-00001\n",
            "ckpt-277200.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "X0HcyiildG7L",
        "outputId": "cf6efaba-b7cf-4282-cdc5-8126e99cd9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow/workspace/pretrained_models\n"
          ]
        }
      ],
      "source": [
        "print(paths['PRETRAINED_MODEL_PATH'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUN_SCNhdG7M"
      },
      "source": [
        "If your network connection is not reliable or is running slowly, you can download the model directly from [this link](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz). Once downloaded, you can unzip the file using a tool like WinRAR.\n",
        "\n",
        "Ensure that you extract the model to the following location: `tensorflow/workspace/pretrained_models`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OanNefavdG7M"
      },
      "source": [
        "## 3.3 **Create a Label Map**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjqMb1uvdG7M"
      },
      "source": [
        "our labels consist of numbers from 0 to 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rt8UDjMMdG7M"
      },
      "outputs": [],
      "source": [
        "labels = [\n",
        "    {'name':'0', 'id':1},\n",
        "    {'name':'1', 'id':2},\n",
        "    {'name':'2', 'id':3},\n",
        "    {'name':'3', 'id':4},\n",
        "    {'name':'4', 'id':5},\n",
        "    {'name':'5', 'id':6},\n",
        "    {'name':'6', 'id':7},\n",
        "    {'name':'7', 'id':8},\n",
        "    {'name':'8', 'id':9},\n",
        "    {'name':'9', 'id':10}\n",
        "]\n",
        "\n",
        "# here, a label map file is being created where each label is defined with its name and ID\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0v_kVx27dG7N",
        "outputId": "4110d84c-110b-4510-c7c4-e1506da2ba90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow/workspace/annotations/label_map.pbtxt\n"
          ]
        }
      ],
      "source": [
        "print(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3402VYLdG7N"
      },
      "source": [
        "## **3.4 Create TF records**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "-44-PzeegUyU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PPT4kOdMdG7N"
      },
      "outputs": [],
      "source": [
        "# clone nicks tf python script\n",
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HzEHzfAFdG7N",
        "outputId": "bc463900-3dc9-40ec-fbcf-6f4f3c90428b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2023.3.post1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dZE1GAFldG7N",
        "outputId": "3ee57ebd-5c18-4720-85e5-276675cc913d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8QIWkeQ2dG7O",
        "outputId": "7c214b64-9f0a-4185-b6ce-f38767b83084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow/workspace/pretrained_models\n"
          ]
        }
      ],
      "source": [
        "print(paths['PRETRAINED_MODEL_PATH'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW5_RYeYdG7O"
      },
      "source": [
        "what the code does is basically running the python script inside of tf_record_script, opens up the image source file in train/test, opens up the labelmap folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HGWYjRFdG7O"
      },
      "source": [
        "## 3.4 **copy model config to training folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "WV5IfuJAdG7O",
        "outputId": "f8dccdb3-0fd5-4ea1-f7d2-c6b48157e411",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'tensorflow/workspace/pretrained_models/spinenet49mobile/pipeline.config': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "if os.name == 'posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_SSnQUdG7P"
      },
      "source": [
        "## 3.5 **Update Config to Training Folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LpY_Mh3YdG7P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util #manipulate config files\n",
        "from object_detection.protos import pipeline_pb2 #define pipeline configs\n",
        "from google.protobuf import text_format #covert config files into protobuf n human text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nYumn6VbdG7P"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGbAv6m7dG7P",
        "outputId": "6a4c405d-9750-4979-c0e6-345ea69e5c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xFTd6DhidG7P"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], 'r') as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SWUosohldG7Q"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Vk2K52JLdG7Q"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], 'wb') as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqKzti18dG7Q"
      },
      "source": [
        "## 3.5 *Train The Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "aAg7nIkkdG7Q"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths[\"APIMODEL_PATH\"], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4QyUSvuMdG7Q"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=1000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR5kxqIMdG7R",
        "outputId": "03a6e86f-5b9b-4799-de89-5ffd620c93f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=1000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "metadata": {
        "id": "w6g5t8YG0x32"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt==8.6.1"
      ],
      "metadata": {
        "id": "NM3xDsZWrQbS",
        "outputId": "88c2c47f-9986-4255-d9ea-fec0a7832733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt==8.6.1\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16971 sha256=6e88791936e71d6d557ccd0c0606594b982d03c5955ede98b88879ff55d6ba0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-8.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lWn2mkJldG7R",
        "outputId": "9ae06c39-47c9-4082-9b0d-4156224bcc30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-17 08:06:09.910187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I1017 08:06:23.628442 136989618425856 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 1000\n",
            "I1017 08:06:23.709853 136989618425856 config_util.py:552] Maybe overwriting train_steps: 1000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1017 08:06:23.710161 136989618425856 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1017 08:06:23.747901 136989618425856 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['tensorflow/workspace/annotations/train.record']\n",
            "I1017 08:06:23.767387 136989618425856 dataset_builder.py:162] Reading unweighted datasets: ['tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['tensorflow/workspace/annotations/train.record']\n",
            "I1017 08:06:23.767760 136989618425856 dataset_builder.py:79] Reading record datasets for input file: ['tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1017 08:06:23.767902 136989618425856 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1017 08:06:23.767997 136989618425856 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1017 08:06:23.793025 136989618425856 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1017 08:06:23.828344 136989618425856 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1017 08:06:32.868258 136989618425856 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1017 08:06:38.889189 136989618425856 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1017 08:06:42.339227 136989618425856 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2023-10-17 08:06:47.506529: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "2023-10-17 08:06:54.786087: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2023-10-17 08:06:54.888384: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2023-10-17 08:06:55.004621: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 83867616 exceeds 10% of free system memory.\n",
            "2023-10-17 08:06:55.105709: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2023-10-17 08:06:55.108027: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 83867616 exceeds 10% of free system memory.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I1017 08:07:13.860146 136987259418176 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1017 08:07:26.619852 136987259418176 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "2023-10-17 08:07:38.817010: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1017 08:07:40.093618 136987292988992 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I1017 08:07:41.656631 136987292988992 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1017 08:07:51.734028 136987292988992 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1017 08:08:01.310442 136987292988992 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I1017 08:08:08.700941 136987292988992 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DwYx262fdG7R",
        "outputId": "39264143-3474-4e03-db54-864699a31c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gin-config==0.1.1\n",
            "  Downloading gin-config-0.1.1.tar.gz (40 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m775.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from gin-config==0.1.1) (1.16.0)\n",
            "Building wheels for collected packages: gin-config\n",
            "  Building wheel for gin-config (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gin-config: filename=gin_config-0.1.1-py3-none-any.whl size=38308 sha256=2fa3652aa75422fb5de9d3b1dbb4e74a8e897fa425ca9190acc8000dd0c72ada\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/ad/a7/b085ddc60427ebf0d52e1643eb4906911866690c004adbcc9d\n",
            "Successfully built gin-config\n",
            "Installing collected packages: gin-config\n",
            "  Attempting uninstall: gin-config\n",
            "    Found existing installation: gin-config 0.5.0\n",
            "    Uninstalling gin-config-0.5.0:\n",
            "      Successfully uninstalled gin-config-0.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gin-config>=0.3.0, but you have gin-config 0.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gin-config-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gin-config==0.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmUFvOzdG7R"
      },
      "source": [
        "\n",
        "# 4. **Training models with resnet**\n",
        "\n",
        "since the old models failed me due to deprecated dependencies, we will use the newer more updated models, following this  [tutorial](https://www.tensorflow.org/tfmodels/vision/object_detection)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Install necessary dependancies"
      ],
      "metadata": {
        "id": "oREknNt5QhbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"tensorflow\" \"tf-models-official\""
      ],
      "metadata": {
        "id": "PfIHVRmQQE2t",
        "outputId": "edc1124a-3be0-47f2-dd96-eeef70b63c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Import necessary libraries"
      ],
      "metadata": {
        "id": "HT-57bkTQ9tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import pprint\n",
        "import tempfile\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from six import BytesIO\n",
        "from IPython import display\n",
        "from urllib.request import urlopen"
      ],
      "metadata": {
        "id": "L9u6qvlxRCdK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Import necessary tensorflow libraries"
      ],
      "metadata": {
        "id": "TgVVfxNiRItj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import orbit\n",
        "import tensorflow_models as tfm\n",
        "\n",
        "from official.core import exp_factory\n",
        "from official.core import config_definitions as cfg\n",
        "from official.vision.serving import export_saved_model_lib\n",
        "from official.vision.ops.preprocess_ops import normalize_image\n",
        "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
        "from official.vision.utils.object_detection import visualization_utils\n",
        "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
        "print(tf.__version__) # Check the version of tensorflow used\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Y4b73mczRDOq",
        "outputId": "dc3b6187-ab86-46cc-a572-aaf55d8e724d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Clone the model garden repo"
      ],
      "metadata": {
        "id": "H8ascVkiRUii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "uQgWlNe-RDLb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 convert data (train data)"
      ],
      "metadata": {
        "id": "zJ_1WddoSLAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TRAINING_PATH = os.path.join('tensorflow', 'workspace','images', 'train')\n",
        "TESTING_PATH = os.path.join('tensorflow', 'workspace','images', 'test')"
      ],
      "metadata": {
        "id": "rVraYaf6SBcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(TRAINING_PATH) or not os.path.exists(TESTING_PATH):\n",
        "    if os.name == 'posix':\n",
        "        !mkdir -p {TRAINING_PATH}\n",
        "        !mkdir -p {TESTING_PATH}\n",
        "    if os.name == 'nt':\n",
        "        !mkdir {TRAINING_PATH}\n",
        "        !mkdir {TESTING_PATH}"
      ],
      "metadata": {
        "id": "WchYiQVpSBYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copy-paste images plus respective annotations to train and test folders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "L99KPaQ0TuqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since they are all in local machine, we will upload them from google drive\n",
        "#/content/tensorflow/workspace/images   /content/drive/MyDrive/tensorflow-object-detection-main/tensorflow/workspace/images\n",
        "!cp -r /content/drive/MyDrive/tensorflow-object-detection-main/tensorflow/workspace/images /content/tensorflow/workspace/\n"
      ],
      "metadata": {
        "id": "XvMV1v2KSBWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fuzHC_wRSBSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7X9RCdPdG7R"
      },
      "source": [
        "\n",
        "# 5. **Freezing and Conversion**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaP3T41PdG7S"
      },
      "source": [
        "\n",
        "# 6. **Performance Tuning**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOyaXaw7dG7S"
      },
      "source": [
        "\n",
        "# 7. **Packaging**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFKO8Z50dG7S"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8umfmSCdG7S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}